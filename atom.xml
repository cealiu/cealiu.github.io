<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LiuCe&#39;s Blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://cealiu.me/"/>
  <updated>2020-06-02T12:04:38.388Z</updated>
  <id>http://cealiu.me/</id>
  
  <author>
    <name>LiuCe</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>spring cloud使用</title>
    <link href="http://cealiu.me/2020/06/02/spring-cloud%E4%BD%BF%E7%94%A8/"/>
    <id>http://cealiu.me/2020/06/02/spring-cloud使用/</id>
    <published>2020-06-02T12:02:06.000Z</published>
    <updated>2020-06-02T12:04:38.388Z</updated>
    
    <content type="html"><![CDATA[<h3 id="写在文章前"><a href="#写在文章前" class="headerlink" title="写在文章前"></a>写在文章前</h3><p>因为最近工作比较忙基本是996的状态还有自己的私事要处理，所以好久没有整理过自己的博客。趁着空闲时间记录下之前工作和平时遇到的问题，便于后面查阅。</p>
<p>这段时间工作之余将之前的风控系统用flink流式框架进行了重写，并计划用Spring cloud与vue admin做一个可视化框架，使这套框架能成为通用的规则处理引擎，后面会专门写文章进行介绍，先放上github地址吧。</p>
<p><a href="https://github.com/cealiu/StreamRule" target="_blank" rel="noopener">flink流式规则处理</a></p>
<p><a href="https://github.com/cealiu/rule-system" target="_blank" rel="noopener">spring cloud后台</a></p>
<p><a href="https://github.com/cealiu/rule-system-vue" target="_blank" rel="noopener">vue admin前端</a></p>
<h4 id="工作中遇到的问题"><a href="#工作中遇到的问题" class="headerlink" title="工作中遇到的问题"></a>工作中遇到的问题</h4><ol>
<li><p>工作中之前使用cat组件进行apm性能监控，使用开源版本下来有各种各样的问题，自己增加了些功能，也解决了写bug但是没来及提交问题，后面有时间也下记录吧。在新的项目重构中已经弃用了cat方案，选用了skywalking。</p>
</li>
<li><p>另一方面在对公司项目重构的过程中使用了spring cloud框架，注册中心使用nacos，遇到偶尔情况下应用会疯狂刷日志的情况，这个问题是由于nacos client与nacos server对同一个配置文本进行md5时两端的md5值不一致导致的，服务端的md5值首位0会丢失，解决了这个bug但是也没来得及提交…</p>
<p>这个bug官方在1.3版本中已经解决了，但是将md5加密的方法都进行了重写，没有在老方法基础上进行更改。</p>
</li>
</ol>
<h4 id="spring-cloud使用中遇到的问题"><a href="#spring-cloud使用中遇到的问题" class="headerlink" title="spring cloud使用中遇到的问题"></a>spring cloud使用中遇到的问题</h4><p>最近比较忙是要将公司的项目进行重构并选用了spring cloud框架，网关使用spring cloud gateway，注册中心使用nacos等，使用feign进行协议传输项目基本完成到一定阶段后进行了压测并遇到了一些问题这里记录下遇到的问题。</p>
<ol>
<li><p>Spring cloud gateway的调优，spring cloud gateway使用webflux方案底层使用netty框架。在压测过程中网关性能始终上不来，处理能力还不如直接访问应用本身来的快，查阅资料后进行了一些参数调整，调整后的启动参数如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-Dreactor.netty.pool.maxConnections=1000</span><br><span class="line">-Dreactor.netty.ioWorkerCount=32</span><br></pre></td></tr></table></figure>
<p>起主要作用的是对ioWorkerCount值的设置，work是netty处理请求的thread，该值默认等于处理器数量最小值为4。具体的介绍可以看有关netty框架的介绍。</p>
</li>
<li><p>压测过程中还碰到大量并发访问系统过程中，作为fegin server的一端会产生大量的tcp time_wait的连接，这其实是由于tcp client已经断开但是tcp server端还会有一段时间等待断连。这个知识涉及到tcp协议的三次握手与四次挥手，之前只在面试中被问到过，现在总算遇到了场景(逃…)</p>
<p>解决办法是调整系统参数可以解决，调整这些参数也只是为了应对系统大并发，系统并发不是很大的话可以不调整的，在Linux系统/etc/sysctl.conf文件中加入如下值，具体意义可以百度到</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line">net.ipv4.tcp_fin_timeout = 30</span><br></pre></td></tr></table></figure>
</li>
<li><p>还遇到的一个情况是fegin碰到数据发送超时会进行重试，但是有些业务场景尤其是金融相关的情况，即便是网络超时也不进行重试(有可能对方已经收到了数据，但是响应超时，尤其是对接第三方接口的情况下)，所以我们关闭了feign的超时重试机制。</p>
</li>
<li><p>一个小改动方面是在使用nacos的过程中，应用的配置信息在启动或者刷新配置的时候会将配置信息打印到日志中，配置信息有可能包含一些敏感信息不符合PCI安全规范，所以也在启动过程中进行屏蔽，启动参数中加入如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-Dlogging.level.com.alibaba.cloud.nacos.client.NacosPropertySourceBuilder=ERROR</span><br><span class="line">-Dlogging.level.com.alibaba.nacos.client.config.impl.ClientWorker=ERROR</span><br></pre></td></tr></table></figure>
<p>加入远程nacos并不能生效，加入到bootstrap.properties会生效，但是要所有应用都要改动，所以添加到了启动参数中。另外其实远程生效也是可以实现的这个跟alibaba spring cloud nacos的代码有关，在上面的参数类中都没有加入@refreshscope注解所以不会生效。</p>
</li>
</ol>
<h4 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h4><p>随着工作强度加大和年纪增大家庭琐事也会越来越多，也只能靠工作和平时碎片时间进行学习和记录一点东西，下次想写一些自己阅读的一些开源代码和解决的一些开源bug，希望以后自己能多有一些时间多读读书，多动动笔……</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;写在文章前&quot;&gt;&lt;a href=&quot;#写在文章前&quot; class=&quot;headerlink&quot; title=&quot;写在文章前&quot;&gt;&lt;/a&gt;写在文章前&lt;/h3&gt;&lt;p&gt;因为最近工作比较忙基本是996的状态还有自己的私事要处理，所以好久没有整理过自己的博客。趁着空闲时间记录下之前工作和
    
    </summary>
    
    
      <category term="java" scheme="http://cealiu.me/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>web控制树莓派led</title>
    <link href="http://cealiu.me/2019/09/21/web%E6%8E%A7%E5%88%B6%E6%A0%91%E8%8E%93%E6%B4%BEled/"/>
    <id>http://cealiu.me/2019/09/21/web控制树莓派led/</id>
    <published>2019-09-21T02:44:09.000Z</published>
    <updated>2019-09-21T05:32:14.126Z</updated>
    
    <content type="html"><![CDATA[<p>​      最近树莓派4b发布女朋友买了个4g版本当七夕礼物送我，买来随便研究了下硕士的时候做嵌入式所以对硬件底层比较了解就先拿来做了点灯的小程序试试效果。效果就是通过网页web点击button控制树莓派连接的led灯的亮灭，用的技术栈有python、vue、django等。</p>
<h3 id="硬件连接"><a href="#硬件连接" class="headerlink" title="硬件连接"></a>硬件连接</h3><p>要通过树莓派引脚(GPIO)控制led，需要做如下连接:</p>
<p><img src="/images/led.png" alt=""></p>
<p>上图是网上找的一个大概示意图，led的两个引脚一端接地另外一端接GPIO，也可以一端接电源另外一端接GPIO引脚，别管怎么接主要目的就是通过控制GPIO输出高低电平来实现led的亮灭。led需要的电流比较小，所以要加电阻控制下，如果要通过GPIO控制大电流或者电压设备就需要到三极管或者继电器等元器件。  </p>
<p>树莓派专门提供了python包RPi.GPIO来控制GPIO引脚，如果复杂功能或者驱动的话需要用到C语言的包，这个大家可以网上自己找下资料。</p>
<h3 id="web搭建"><a href="#web搭建" class="headerlink" title="web搭建"></a>web搭建</h3><p>web后台使用Django的rest framework，前端使用vue框架。</p>
<ol>
<li><p>Django后台搭建：</p>
<p>Python3可以直接创建虚拟环境，使用以下命令创建：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir led</span><br><span class="line">cd led</span><br><span class="line">python -m venv venv</span><br><span class="line">pip install django</span><br><span class="line">pip install djangorestframework</span><br><span class="line">...</span><br><span class="line">pip install RPi.GPIO</span><br></pre></td></tr></table></figure>
<p>Django rest framework (安装文档)[<a href="https://www.django-rest-framework.org]，另外要注意安装RPi.GPIO要在树莓派上安装在本地电脑会报错。" target="_blank" rel="noopener">https://www.django-rest-framework.org]，另外要注意安装RPi.GPIO要在树莓派上安装在本地电脑会报错。</a></p>
</li>
<li><p>vue前端搭建：</p>
<p>前端使用的是vue用的iview框架，这部分网上内容挺多的以下是官方的安装文档，安装之前请先装node环境：</p>
<p>(vue安装)[<a href="https://cn.vuejs.org/v2/guide/installation.html#NPM" target="_blank" rel="noopener">https://cn.vuejs.org/v2/guide/installation.html#NPM</a>]</p>
<p>(iview安装)[<a href="https://www.iviewui.com/docs/guide/start#SYZQ" target="_blank" rel="noopener">https://www.iviewui.com/docs/guide/start#SYZQ</a>]</p>
</li>
</ol>
<p>###部署</p>
<ol>
<li><p>以上都完成了，需要部署在树莓派上，我在树莓派上安装了nginx做转发：</p>
<p>ssh到树莓派上安装nginx，如果安装报网络错误要更换下apt源</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nginx</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装完成后将前后台项目拷贝到树莓派上，我的目录是：</p>
<p>后台Django: /home/pi/test/led</p>
<p>前端vue: /home/pi/dist</p>
</li>
<li><p>配置nginx转发，找到nginx的配置目录，增加led.conf文件，并添加如下内入</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span>       <span class="number">80</span>;<span class="comment">#默认端口是80，如果端口没被占用可以不用修改</span></span><br><span class="line">        <span class="attribute">server_name</span>  <span class="number">192.168.2.167</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#charset koi8-r;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#access_log  logs/host.access.log  main;</span></span><br><span class="line">        <span class="attribute">root</span>        /home/pi/dist;<span class="comment">#vue项目的打包后的dist</span></span><br><span class="line"></span><br><span class="line">        <span class="attribute">location</span> / &#123;</span><br><span class="line">            <span class="attribute">try_files</span> <span class="variable">$uri</span> <span class="variable">$uri</span>/ <span class="variable">@router</span>;<span class="comment">#需要指向下面的@router否则会出现vue的路由在nginx中刷新出现404</span></span><br><span class="line">            <span class="attribute">index</span>  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">#对应上面的@router，主要原因是路由的路径资源并不是一个真实的路径，所以无法找到具体的文件</span></span><br><span class="line">        <span class="comment">#因此需要rewrite到index.html中，然后交给路由在处理请求资源</span></span><br><span class="line">        <span class="attribute">location</span> <span class="variable">@router</span> &#123;</span><br><span class="line">            <span class="attribute">rewrite</span><span class="regexp"> ^.*$</span> /index.html <span class="literal">last</span>;</span><br><span class="line">        &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动：</p>
<p>启动nginx: sudo /etc/init.d/nginx start</p>
<p>启动django: python3 manage.py runserver 0.0.0.0:8000 &amp;</p>
</li>
<li><p>Django部署也可以使用nginx+uwsgi方式，这里我就没在弄了，大家可以去网上搜集下资料</p>
</li>
<li><p>实现效果要求网页端和树莓派无线在一个局域网内，想要外网连接实现的话，需要有个域名外加上内网穿透工具实现，代码里都是用ip地址指向的运行的时候要改为实际ip或域名</p>
</li>
</ol>
<h3 id="源码与效果"><a href="#源码与效果" class="headerlink" title="源码与效果"></a>源码与效果</h3><ol>
<li>源码我上传到了我的github上，仓库地址是：<a href="https://github.com/cealiu/led" target="_blank" rel="noopener">led</a></li>
<li>演示地址: <a href="https://www.bilibili.com/video/av68470271/" target="_blank" rel="noopener">B站</a></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;​      最近树莓派4b发布女朋友买了个4g版本当七夕礼物送我，买来随便研究了下硕士的时候做嵌入式所以对硬件底层比较了解就先拿来做了点灯的小程序试试效果。效果就是通过网页web点击button控制树莓派连接的led灯的亮灭，用的技术栈有python、vue、django
    
    </summary>
    
    
      <category term="web, python" scheme="http://cealiu.me/tags/web-python/"/>
    
  </entry>
  
  <entry>
    <title>风控规则系统开发</title>
    <link href="http://cealiu.me/2018/09/05/%E9%A3%8E%E6%8E%A7%E8%A7%84%E5%88%99%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91/"/>
    <id>http://cealiu.me/2018/09/05/风控规则系统开发/</id>
    <published>2018-09-05T13:30:22.000Z</published>
    <updated>2018-09-05T14:08:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>公司需要开发风控系统之前没有接触过这一块，在网上查询好多资料或得的一些思路，开发的过程也走了些弯路踩了不少坑现在记录下来。</p>
<p>对于风控来说就是提前预防风险降低安全事故的发生，并且能及早发现和封堵；在前期的探索阶段都是利用日志或者离线数据发现规律，在做下面的实时风控系统之前，前期是利用ELK记录的日志数据来查找规律发现一些问题的。</p>
<h3 id="常见风险："><a href="#常见风险：" class="headerlink" title="常见风险："></a>常见风险：</h3><p>研究风控之前有一些风险是比较常出现的：</p>
<ol>
<li>利用机器访问：爬虫、频繁调用短信接口、垃圾注册等</li>
<li>人为原因：薅羊毛、金融盗刷等</li>
</ol>
<h3 id="风控系统"><a href="#风控系统" class="headerlink" title="风控系统"></a>风控系统</h3><p>风控系统分为实时风控和非实时风控系统，两种用途不太一样实时系统可以快速拦截风险，非实时离线系统可以发现一些未知风险。</p>
<h4 id="离线系统"><a href="#离线系统" class="headerlink" title="离线系统"></a>离线系统</h4><p>离线系统前期更多的是用于数据分析和发现规律，可以利用已知风险数据和一些机器学习的方法发现一些风险点；同时离线数据也可以为实时系统提供信息决策。前期做离线分析的时候用过相关性分析、决策树、k临近算法等等。</p>
<h4 id="实时系统"><a href="#实时系统" class="headerlink" title="实时系统"></a>实时系统</h4><p>实时系统对系统的响应比较高，本次项目就是利用drools规则引擎可以迅速的更改规则不必重新部署就可以做到发现和拦截一些风险访问。</p>
<h5 id="主要技术点"><a href="#主要技术点" class="headerlink" title="主要技术点"></a>主要技术点</h5><p>公司访问量比较订单一天大于2000w单，技术框架采用的是kakfa，spark-streaming、drools、redis、postgresql，下面是系统的一个总体框架图</p>
<p><img src="/images/riskrule.jpeg" alt=""></p>
<p>drools规则放置在postgresql数据库可以实时更改规则，redis作为临时数据缓存，加载历史数据可以通过历史发现一些发现，例如交易总不在固定地点、多次查询余额等等；通过运行发现处理速度还是不错的，性能瓶颈主要在缓存数据的获取上，总体运行下来单台redis的处理性能达到每数4w/s左右效率还是不错的。</p>
<p>把部分代码提交到了我的<a href="https://github.com/cealiu/RiskRule" target="_blank" rel="noopener">github</a>上。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;公司需要开发风控系统之前没有接触过这一块，在网上查询好多资料或得的一些思路，开发的过程也走了些弯路踩了不少坑现在记录下来。&lt;/p&gt;
&lt;p&gt;对
    
    </summary>
    
    
      <category term="bigdata" scheme="http://cealiu.me/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>python requests post丢失数据</title>
    <link href="http://cealiu.me/2018/05/14/python-requests-post%E4%B8%A2%E5%A4%B1%E6%95%B0%E6%8D%AE/"/>
    <id>http://cealiu.me/2018/05/14/python-requests-post丢失数据/</id>
    <published>2018-05-14T12:58:28.000Z</published>
    <updated>2018-05-14T13:12:55.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h3><p>这周遇到一个bug使用python的requests lib单独运行脚本post数据就成功，结果使用django调用该函数就出问题。在后台打印log发现django调用的时候request.body丢失了部分数据。</p>
<p>代码类似：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">body=dict()</span><br><span class="line">body[<span class="string">'token'</span>]=<span class="string">'23sdcwo81mdvlpwcva'</span></span><br><span class="line">body[<span class="string">'content'</span>]=<span class="string">'信息'</span></span><br><span class="line">...</span><br><span class="line">request.post(data = json.dumps(data,ensure_ascii=<span class="keyword">False</span>))</span><br></pre></td></tr></table></figure>
<p>原因是单独调用代码的时候发送的body数据内容都是str类型，而Django调用的时候引入了unicode类型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test = <span class="string">'test'</span></span><br><span class="line"><span class="keyword">print</span> type(test)   <span class="comment">#str</span></span><br><span class="line">test = <span class="string">'test'</span> + unicode(<span class="string">'test'</span>)</span><br><span class="line"><span class="keyword">print</span> type(test)   <span class="comment">#unicode</span></span><br></pre></td></tr></table></figure>
<h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>这个跟python的自身编码问题有关，python3加requests能够解决这个问题，但是项目是python2.7的所以用其它方式解决。在requests lib断点调试下会发现init.py—&gt; api.py—&gt;models.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.headers[<span class="string">'Content-Length'</span>] = builtin_str(l) <span class="comment">#477 line</span></span><br></pre></td></tr></table></figure>
<p>将body内的数据转化为str类型解决，或者在增加headers解决</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">request.post(data = json.dumps(data,ensure_ascii=<span class="keyword">False</span>),headers=&#123;<span class="string">'Content-Length'</span>:str(len(data))&#125;)</span><br></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;描述&quot;&gt;&lt;a href=&quot;#描述&quot; class=&quot;headerlink&quot; title=&quot;描述&quot;&gt;&lt;/a&gt;描述&lt;/h3&gt;&lt;p&gt;这周遇到一个bug使用python的requests lib单独运行脚本post数据就成功，结果使用django调用该函数就出问题。在后台打
    
    </summary>
    
    
      <category term="python" scheme="http://cealiu.me/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>朴素贝叶斯</title>
    <link href="http://cealiu.me/2018/05/13/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    <id>http://cealiu.me/2018/05/13/朴素贝叶斯/</id>
    <published>2018-05-13T10:24:22.000Z</published>
    <updated>2018-05-21T13:01:02.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h3><p>贝叶斯公式：$P(A|B)=P(AB)/P(B)$</p>
<p>$P(A|B)$表示在B条件下A事件发生的概率，其中$P(A)$表示先验概率，P(A|B)代表后验概率即在B事件发生之后，我们对A事件概率的重新评估，这使得预估概率更接近真实概率。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;基本方法&quot;&gt;&lt;a href=&quot;#基本方法&quot; class=&quot;headerlink&quot; title=&quot;基本方法&quot;&gt;&lt;/a&gt;基本方法&lt;/h3&gt;&lt;p&gt;贝叶斯公式：$P(A|B)=P(AB)/P(B)$&lt;/p&gt;
&lt;p&gt;$P(A|B)$表示在B条件下A事件发生的概率，其中$P(
    
    </summary>
    
    
      <category term="机器学习" scheme="http://cealiu.me/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>车牌识别</title>
    <link href="http://cealiu.me/2018/05/08/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/"/>
    <id>http://cealiu.me/2018/05/08/车牌识别/</id>
    <published>2018-05-08T13:48:23.000Z</published>
    <updated>2018-09-05T13:35:38.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="车牌识别"><a href="#车牌识别" class="headerlink" title="车牌识别"></a>车牌识别</h3><p>最近帮朋友调一个车牌识别的源码<a href="https://github.com/zeusees/HyperLPR" target="_blank" rel="noopener">开源地址</a>有些地方要改动才能跑起来，该项目是基于opencv、深度学习DNN算法做的车牌识别，该blog主要是记录下踩坑过程。</p>
<h3 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h3><h4 id="opencv环境搭建"><a href="#opencv环境搭建" class="headerlink" title="opencv环境搭建"></a>opencv环境搭建</h4><p>项目是基于python开发的，但是底层还是依赖opencv的c++库，所以环境搭建最主要的还是opencv的配置；我是基于mac系统做的，开源版本要求opencv版本大于3.3所以用brew install安装的版本不适合。</p>
<ol>
<li><p>编译安装</p>
<p>去官网下载最新版本<a href="https://opencv.org/" target="_blank" rel="noopener">opencv</a>， 之后安装cmake<a href="https://cmake.org/" target="_blank" rel="noopener">地址</a>。我下载的是图形界面版的；之后在opencv源码内新建release文件夹，打开cmake</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;车牌识别&quot;&gt;&lt;a href=&quot;#车牌识别&quot; class=&quot;headerlink&quot; title=&quot;车牌识别&quot;&gt;&lt;/a&gt;车牌识别&lt;/h3&gt;&lt;p&gt;最近帮朋友调一个车牌识别的源码&lt;a href=&quot;https://github.com/zeusees/HyperLPR&quot; t
    
    </summary>
    
    
      <category term="bigdata" scheme="http://cealiu.me/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>openstack源码分析一</title>
    <link href="http://cealiu.me/2018/01/23/openstack%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80/"/>
    <id>http://cealiu.me/2018/01/23/openstack源码分析一/</id>
    <published>2018-01-23T13:09:10.000Z</published>
    <updated>2018-01-23T13:43:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>从openstack的nova开始先介绍，在openstack的组件中，基本每个组件都会有一个API服务，对于Nova来说API服务主要的作用就是接收由用户通过Client或者一些其他REST请求工具（比如curl、postman）发送的请求。一般来说会包含一些虚拟机创建的参数，比如虚拟机的规格、可用域之类的信息。</p>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>我们在启动nova-api会使用service openstack-nova-api start命令，查看该服务启动的是/usr/bin/nova-api</p>
<ol>
<li><p>nova/cmd/api.py    def main():  #启动进程</p>
<p>功能：载入配置文件、启动进程数（默认cpu核数）、根据配置文件中的enabled_apis启动不同WSGIService</p>
<p>nova.conf</p>
<p>enabled_apis=ec2,osapi_compute,metadata</p>
<p>ec2 亚马逊云主机</p>
<p>osapi_compute openstack云主机</p>
<p>metadata 元数据</p>
<p>我们主要看osapi_compute</p>
</li>
<li><p>nova/service.py class WSGIService(service.Service):</p>
<p>功能加载/etc/nova/api-paste.ini（这里用到了deploy模块解释：<a href="https://www.cnblogs.com/Security-Darren/p/4087587.html" target="_blank" rel="noopener">https://www.cnblogs.com/Security-Darren/p/4087587.html</a>）</p>
</li>
<li><p>etc/nova/api-paste.ini</p>
<p>[composite:osapi_compute]</p>
<p>use = call:nova.api.openstack.urlmap:urlmap_factory</p>
<p>解析url调用 urlmap_factory</p>
</li>
<li><p>nova/api/openstack/urlmap.py</p>
<p>def urlmap_factory(loader, global_conf, **local_conf):</p>
<p>#loader是上面加在的app的loader，这里是osapi_compute</p>
<p>#global_conf = {‘<strong>file</strong>‘: ‘/etc/nova/api-paste.ini’, ‘here’: ‘/etc/nova’}</p>
<p>#local_conf = {‘/v2’: ‘openstack_compute_api_v21_legacy_v2_compatible’, ‘/‘: ‘oscomputeversions’, ‘/v2.1’: ‘openstack_compute_api_v21’}</p>
<p>该方法将osapi_compute 转换为 openstack_compute_api_v21_legacy_v2_compatible</p>
<p>[composite:openstack_compute_api_v21_legacy_v2_compatible]</p>
<p>use = call:nova.api.auth:pipeline_factory_v21</p>
<p>noauth2 = cors http_proxy_to_wsgi compute_req_id faultwrap request_log sizelimit osprofiler noauth2 legacy_v2_compatible osapi_compute_app_v21</p>
<p>keystone = cors http_proxy_to_wsgi compute_req_id faultwrap request_log sizelimit osprofiler authtoken keystonecontext legacy_v2_compatible osapi_compute_app_v21</p>
</li>
<li><p>nova/api/auth.py</p>
<p>def pipeline_factory_v21(loader, global_conf, **local_conf): </p>
<p>#使用keystone验证 类似Django midware看keystone最后一项osapi_compute_app_v21</p>
</li>
<li><p>[app:osapi_compute_app_v21]</p>
<p>paste.app_factory = nova.api.openstack.compute:APIRouterV21.factory</p>
<p>Nova/api/openstack/compute/routes.py</p>
<p>class APIRouterV21(base_wsgi.Router): #最终url解析（flavor、show…）</p>
<p>贴一个调用流程图，新版加入了nova-cell这里是个简易版</p>
<p><img src="/images/nova.png" alt=""></p>
<p>​</p>
<p>先介绍这里，剩下就是nova-conductor、nova-scheduler、nova-coumpute的rpc调用</p>
</li>
</ol>
<h5 id="to-be-continued"><a href="#to-be-continued" class="headerlink" title="to be continued"></a>to be continued</h5>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;从openstack的nova开始先介绍，在openstack的组件中，基本每个组件都会有一个API服务，对于Nova来说API服务主要的作用就是接收由用户通过Client或者一些其他REST请求工具（比如curl、postman）发送的请求。一般来说会包含一些虚拟机创建的
    
    </summary>
    
    
      <category term="cloud" scheme="http://cealiu.me/tags/cloud/"/>
    
  </entry>
  
  <entry>
    <title>openstack概念整理</title>
    <link href="http://cealiu.me/2017/12/19/openstack%E6%A6%82%E5%BF%B5%E6%95%B4%E7%90%86/"/>
    <id>http://cealiu.me/2017/12/19/openstack概念整理/</id>
    <published>2017-12-19T02:44:07.000Z</published>
    <updated>2019-06-19T02:47:50.173Z</updated>
    
    <content type="html"><![CDATA[<h2 id="openstack-概念整理"><a href="#openstack-概念整理" class="headerlink" title="openstack 概念整理"></a>openstack 概念整理</h2><h3 id="keystone"><a href="#keystone" class="headerlink" title="keystone"></a>keystone</h3><p>V2：</p>
<p>Tenant、User、Role</p>
<p>V3</p>
<p>Domain、Project、Group、User、Role</p>
<p>例子：使用OpenStack搭建公司的私有云V2版本的keystone基本够用</p>
<p>Tenant -&gt; 部门，User-&gt;用户，Role-&gt;权限</p>
<p>现在基于OpenStack构建公有云对每家公司用户来说都会有V2架构，V3多出domain类似公司</p>
<p>Domain-&gt;公司，Project-&gt;部门，User-&gt;用户，Role-&gt;权限，Group-&gt;组（包含给多个user赋权限）</p>
<h3 id="区域概念"><a href="#区域概念" class="headerlink" title="区域概念"></a>区域概念</h3><ul>
<li>region：更像是一个地理上的概念，每个region有自己独立的endpoint，regions之间完全隔离，但是多个regions之间共享同一个keystone和dashboard。（注：目前openstack的dashboard还不支持多region）所以除了提供隔离的功能，region的设计更多侧重地理位置的概念，用户可以选择离自己更近的region来部署自己的服务。</li>
<li>cell：cell是openstack一个非常重要的概念，主要用来解决openstack的扩展性和规模瓶颈。众所周知，openstack是由很多的组件通过松耦合构成，那么当达到一定的规模后，某些模块必然成为整个系统的瓶颈。比较典型的组件就是database和AMQP了，所以，每个cell有自己独立的DB和AMQP。<ul>
<li>cell之间的通信(通过rpc完成)</li>
</ul>
</li>
<li>Availability Zone：AZ可以简单理解为一组节点的集合，这组节点具有独立的电力供应设备，比如一个个独立供电的机房，一个个独立供电的机架都可以被划分成AZ。所以，AZ主要是通过冗余来解决可用性问题。AZ是用户可见的一个概念，用户在创建instance的时候可以选择创建到哪些AZ中，以保证instance的可用性</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;openstack-概念整理&quot;&gt;&lt;a href=&quot;#openstack-概念整理&quot; class=&quot;headerlink&quot; title=&quot;openstack 概念整理&quot;&gt;&lt;/a&gt;openstack 概念整理&lt;/h2&gt;&lt;h3 id=&quot;keystone&quot;&gt;&lt;a href
    
    </summary>
    
    
      <category term="cloud" scheme="http://cealiu.me/tags/cloud/"/>
    
  </entry>
  
  <entry>
    <title>监控总结</title>
    <link href="http://cealiu.me/2017/11/16/%E7%9B%91%E6%8E%A7%E6%80%BB%E7%BB%93/"/>
    <id>http://cealiu.me/2017/11/16/监控总结/</id>
    <published>2017-11-16T00:49:38.000Z</published>
    <updated>2017-12-11T13:54:28.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>年初入职新公司做云计算相关开发奈何线上系统都还有没有做监控，所以接手做监控事宜；</p>
<h4 id="zabbix邮件短信服务"><a href="#zabbix邮件短信服务" class="headerlink" title="zabbix邮件短信服务"></a>zabbix邮件短信服务</h4><p>监控使用的是zabbix将zabbix服务器安装在openstack云服务集群外，zabbix邮件告警直接在配置页面配置好邮件服务器地址；短信告警通过socket对接的是总行的短信服务。</p>
<p>配置如下：</p>
<p><img src="/images/sms.png" alt=""></p>
<p>在图中，Name自行定义；Type选择 Script；Script name填写脚本名称socket_alarm_script.py；Script parameters包含3个参数：{ALERT.SENDTO}、{ALERT.SUBJECT}、{ALERT.MESSAGE}，这3个参数是zabbix启用脚本时自动传给脚本的参数。此3个参数的具体内容将在zabbix文档有具体说明。</p>
<h3 id="主要监控项目"><a href="#主要监控项目" class="headerlink" title="主要监控项目"></a>主要监控项目</h3><p>帮助某家城商行做互金项目监控，主要有tomcat、nginx、redis、oracle、日记</p>
<h4 id="tomcat、nginx、redis、oracle、zookeeper"><a href="#tomcat、nginx、redis、oracle、zookeeper" class="headerlink" title="tomcat、nginx、redis、oracle、zookeeper"></a>tomcat、nginx、redis、oracle、zookeeper</h4><p>tomcat、zookeper监控通过jmx接口来获取jvm监控信息，zabbix页面也支持jmx获取。</p>
<p>nginx通过添加 –with-http_stub_status_module参数编译和在配置文件中</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 127.0.0.1:80;</span><br><span class="line">    server_name 127.0.0.1;</span><br><span class="line">    access_log off;</span><br><span class="line">    allow 127.0.0.1;</span><br><span class="line">    deny all;</span><br><span class="line">    location /nginxstatus &#123;</span><br><span class="line">           stub_status on;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Oracle可以通过orabbix获取，不过我通过pyOrale连接oracle获取的信息</p>
<p>redis通过缓存redis系统信息获取（主要是info里的信息）</p>
<h4 id="日志监控"><a href="#日志监控" class="headerlink" title="日志监控"></a>日志监控</h4><p>本来想用ELK做日志收集监控（城商行不允许这么做），所以选择了zabbix告警日志error信息还好错误信息产生速率不高；</p>
<h4 id="对账文件监控"><a href="#对账文件监控" class="headerlink" title="对账文件监控"></a>对账文件监控</h4><p>平台每天在不同时间段会产生几个对账文件，需要每天检测一次对账文件是否生成；zabbix 3.0支持固定时间点生成告警（粒度一分钟）</p>
<p><img src="/images/zabbix_time.png" alt=""></p>
<h3 id="to-be-contiune"><a href="#to-be-contiune" class="headerlink" title="to be contiune"></a>to be contiune</h3><p>部署选用的ansible，后面补充一些调优配置</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;年初入职新公司做云计算相关开发奈何线上系统都还有没有做监控，所以接手做监控事宜；&lt;/p&gt;
&lt;h4 id=&quot;zabbix邮件短信服务&quot;&gt;&lt;a 
    
    </summary>
    
    
      <category term="linux" scheme="http://cealiu.me/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>集群搭建hadoop问题总结</title>
    <link href="http://cealiu.me/2017/11/01/%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BAhadoop%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
    <id>http://cealiu.me/2017/11/01/集群搭建hadoop问题总结/</id>
    <published>2017-11-01T13:06:12.000Z</published>
    <updated>2017-11-01T13:42:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>在公司的openstack上搭建hadoop的集群环境的过程中遇到一些问题，整理记录下：</p>
<p>搭建的过程参考官方文档和一些blog，版本2.7.4</p>
<ol>
<li><p>申请资源的hadoop的master节点申请public ip，datanode节点可以不用申请public ip。</p>
</li>
<li><p>master节点跟datanode节点设置免密码登录。</p>
</li>
<li><p>搭建完成后运行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>运行不成功，开始报错。</p>
<h4 id="hadoop-java-net-UnknowHostException"><a href="#hadoop-java-net-UnknowHostException" class="headerlink" title="hadoop java.net.UnknowHostException"></a>hadoop java.net.UnknowHostException</h4><p>上面这个错误是不能识别集群的hostname，依次做如下修改：</p>
<ol>
<li>编辑集群中每个/etc/hosts文件，依次将集群的ip hostname记录下来。</li>
<li>编辑/etc/hostname文件，将主机名记录此文件。</li>
<li>编辑 Hadoop/etc/hadoop/slave文件，将datanode的主机名或者datanode的记录下来。</li>
</ol>
<h4 id="FATAL-namenode-NameNode-Exception-in-namenode-join-java-lang-IllegalArgumentException-URI-has-an-authority-component"><a href="#FATAL-namenode-NameNode-Exception-in-namenode-join-java-lang-IllegalArgumentException-URI-has-an-authority-component" class="headerlink" title="FATAL namenode.NameNode: Exception in namenode join java.lang.IllegalArgumentException: URI has an authority component"></a>FATAL namenode.NameNode: Exception in namenode join java.lang.IllegalArgumentException: URI has an authority component</h4><p>出现这个问题有说是配置文件重载权限问题，但是我将hdfs-site.xml的文件权限设置成777也没有生效，后将此文件中的xml配置写成固定值成功，如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop-2.7.4/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span>（即使用完整的绝对地址）  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop-2.7.4/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span>（即使用完整的绝对地址）  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>tmp目录是自己指定的。</p>
<p><strong>完成上述配置后格式化启动成功，发现启动节点数不对或者其他不确定错误，将上面的tmp目录内容清空再试一次即可</strong></p>
<p>放个hadoop配置文件<a href="http://blog.csdn.net/team77/article/details/50205917" target="_blank" rel="noopener">参数介绍</a></p>
<p>之后就可以在上层跑hive，hsql，spark，storm的组件了，map/reduce的开发跟之前单机版一样。</p>
<p>hadoop，es，spark/storm基本思想差不多都是<strong>大化小，小块处理，结果整合</strong>，之前记录过。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在公司的openstack上搭建hadoop的集群环境的过程中遇到一些问题，整理记录下：&lt;/p&gt;
&lt;p&gt;搭建的过程参考官方文档和一些blog，版本2.7.4&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;申请资源的hadoop的master节点申请public ip，datanode节点
    
    </summary>
    
    
      <category term="bigdata" scheme="http://cealiu.me/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>安装linux系统</title>
    <link href="http://cealiu.me/2017/09/17/%E5%AE%89%E8%A3%85linux%E7%B3%BB%E7%BB%9F/"/>
    <id>http://cealiu.me/2017/09/17/安装linux系统/</id>
    <published>2017-09-17T06:46:27.000Z</published>
    <updated>2017-09-17T06:55:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>很久没装过系统了，最近组装台式机安装linux mint系统碰到一点问题：</p>
<ul>
<li><p>用u盘做引导安装过程中所有配置选项做好后点击“继续”出现“无法将grub-efi-amd64-signed软件包安装到/target/中。如果没有GRUB启动引导器，所安装的系统将无法启动”出现这个问题是最新的引导都支持efi引导了；解决方法是在启动列表的选项中选择不带efi u盘的启动项。</p>
</li>
<li><p>进入系统后安装kvm manger后使用图形界面结果显示“Spice doesn’t work from Virtual Machine Manager”linux mint18.2是基于Ubuntu的16.04安装后会出现这个bug，解决办法是执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install gir1.2-spice-client-gtk-3.0</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;很久没装过系统了，最近组装台式机安装linux mint系统碰到一点问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;用u盘做引导安装过程中所有配置选项做好后点击“继续”出现“无法将grub-efi-amd64-signed软件包安装到/target/中。如果没有GRUB启动引导器，
    
    </summary>
    
    
      <category term="linux" scheme="http://cealiu.me/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>hadoop demo程序</title>
    <link href="http://cealiu.me/2017/09/04/hadoop-demo%E7%A8%8B%E5%BA%8F/"/>
    <id>http://cealiu.me/2017/09/04/hadoop-demo程序/</id>
    <published>2017-09-04T03:06:44.000Z</published>
    <updated>2017-09-04T03:15:21.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Map-Reduce介绍"><a href="#Map-Reduce介绍" class="headerlink" title="Map/Reduce介绍"></a>Map/Reduce介绍</h2><p>hadoop主要利用Map/Reduce框架进行快速数据处理，就是将上传到hadoop集群的文件进行分片保存在HDFS上（64M），之后利用Map框架进行预处理后交由Reduce框架处理输出结果，如下图(简易图)：</p>
<p><img src="\images\MapReduce.jpg" alt=""></p>
<h2 id="工程构建"><a href="#工程构建" class="headerlink" title="工程构建"></a>工程构建</h2><p>利用idea建立maven工程，pom.xml配置如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>HadoopTest<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HadoopTest<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.8.0<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-jobclient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>之后建立WordCount.java编译生成jar文件。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">ackage org.myorg;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span> <span class="title">MapReduceBase</span> <span class="keyword">implements</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        String line = value.toString();</span><br><span class="line">        StringTokenizer tokenizer = <span class="keyword">new</span> StringTokenizer(line);</span><br><span class="line">        <span class="keyword">while</span> (tokenizer.hasMoreTokens()) &#123;</span><br><span class="line">            word.set(tokenizer.nextToken());</span><br><span class="line">            output.collect(word, one);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span> <span class="title">MapReduceBase</span> <span class="keyword">implements</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterator&lt;IntWritable&gt; values, OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">            <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span> (values.hasNext()) &#123;</span><br><span class="line">                sum += values.next().get();</span><br><span class="line">            &#125;</span><br><span class="line">            output.collect(key, <span class="keyword">new</span> IntWritable(sum));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        JobConf conf = <span class="keyword">new</span> JobConf(WordCount.class);</span><br><span class="line">        conf.setJobName(<span class="string">"wordcount"</span>);</span><br><span class="line">        conf.setOutputKeyClass(Text.class);</span><br><span class="line">        conf.setOutputValueClass(IntWritable.class);</span><br><span class="line">        conf.setMapperClass(Map.class);</span><br><span class="line">        conf.setCombinerClass(Reduce.class);</span><br><span class="line">        conf.setReducerClass(Reduce.class);</span><br><span class="line"></span><br><span class="line">        conf.setInputFormat(TextInputFormat.class);</span><br><span class="line">        conf.setOutputFormat(TextOutputFormat.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(conf, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(conf, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        JobClient.runJob(conf);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码主要实现了map／reduce处理过程，上节利用命令 -put上传的文件被分配到各个datanode节点。</p>
<p>public void map()按文件行分解为单词输出key/value值</p>
<p>public void reduce()按map传递过来的值统计单词</p>
<p>之后就是在main函数中配置job</p>
<h2 id="程序运行"><a href="#程序运行" class="headerlink" title="程序运行"></a>程序运行</h2><p>上面生成了HadoopTest-1.0-SNAPSHOT.jar</p>
<p>运行命令，会在/user/liuce/output看到输出结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar ./HadoopTest-1.0-SNAPSHOT.jar org.myorg.WordCount /user/liuce/input /user/liuce/output</span><br></pre></td></tr></table></figure>
<p>eclipse下有插件可以远程连接到hadoop服务器上而不用每次做这些上传删除操作，github上只有2.6版本的高级版本可以自己编译，linux、win下插件都没问题但是macos下一直报错，感觉跟mac系统的目录结构有关一直报找不到job。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Map-Reduce介绍&quot;&gt;&lt;a href=&quot;#Map-Reduce介绍&quot; class=&quot;headerlink&quot; title=&quot;Map/Reduce介绍&quot;&gt;&lt;/a&gt;Map/Reduce介绍&lt;/h2&gt;&lt;p&gt;hadoop主要利用Map/Reduce框架进行快速数据处理
    
    </summary>
    
    
      <category term="bigdata" scheme="http://cealiu.me/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>hadoop单机搭建</title>
    <link href="http://cealiu.me/2017/09/04/hadoop%E5%8D%95%E6%9C%BA%E6%90%AD%E5%BB%BA/"/>
    <id>http://cealiu.me/2017/09/04/hadoop单机搭建/</id>
    <published>2017-09-04T02:52:11.000Z</published>
    <updated>2017-09-04T03:05:50.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hadoop-安装"><a href="#Hadoop-安装" class="headerlink" title="Hadoop 安装"></a>Hadoop 安装</h2><p>系统macos 10.12.4，linux系统大体与此相似</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew insall hadoop</span><br></pre></td></tr></table></figure>
<p>该命令安装是是最新版（2.8.0）</p>
<p>配置JAVA_HOME(之前已经配置过，java版本1.8)</p>
<h2 id="配置ssh免密码登录"><a href="#配置ssh免密码登录" class="headerlink" title="配置ssh免密码登录"></a><strong>配置ssh免密码登录</strong></h2><p>1、生成公钥，加入authorized_keys</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>
<h2 id="Hadoop-配置单节点使用"><a href="#Hadoop-配置单节点使用" class="headerlink" title="Hadoop 配置单节点使用"></a>Hadoop 配置单节点使用</h2><p>这里是使用单节点，brew install的hadoop目录在</p>
<p>/usr/local/Cellar/hadoop/2.8.0</p>
<p>配置文件目录在</p>
<p>/usr/local/Cellar/hadoop/2.8.0/libexec/etc/hadoop</p>
<h3 id="配置-hdfs-site-xml"><a href="#配置-hdfs-site-xml" class="headerlink" title="配置 hdfs-site.xml"></a>配置 hdfs-site.xml</h3><p>设置副本数为 <strong>1</strong>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="配置-core-site-xml"><a href="#配置-core-site-xml" class="headerlink" title="配置 core-site.xml"></a>配置 core-site.xml</h3><p>设置文件系统访问的端口：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="配置-mapred-site-xml"><a href="#配置-mapred-site-xml" class="headerlink" title="配置 mapred-site.xml"></a>配置 mapred-site.xml</h3><p>设置 MapReduce 使用的框架：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="配置-yarn-site-xml"><a href="#配置-yarn-site-xml" class="headerlink" title="配置 yarn-site.xml"></a>配置 yarn-site.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="Hadoop运行"><a href="#Hadoop运行" class="headerlink" title="Hadoop运行"></a>Hadoop运行</h2><p>因为没有将hadoop目录环境变量，所以以下命令需要在/usr/local/Cellar/hadoop/2.8.0/libexec/sbin目录下运行。</p>
<h3 id="启动hadoop"><a href="#启动hadoop" class="headerlink" title="启动hadoop"></a>启动hadoop</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>
<h3 id="格式化文件系统"><a href="#格式化文件系统" class="headerlink" title="格式化文件系统"></a>格式化文件系统</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
<h3 id="建立用户空间（相当于连接了hadoop）"><a href="#建立用户空间（相当于连接了hadoop）" class="headerlink" title="建立用户空间（相当于连接了hadoop）"></a>建立用户空间（相当于连接了hadoop）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /user</span><br><span class="line">hdfs dfs -mkdir /user/$(whoami) # 这里是用户</span><br></pre></td></tr></table></figure>
<p>建立好目录后可以使用hadoop命令进行查看了</p>
<p>hadoop fs -ls /user/$(whoami)</p>
<h3 id="查看hadoop启动的进程情况"><a href="#查看hadoop启动的进程情况" class="headerlink" title="查看hadoop启动的进程情况"></a>查看hadoop启动的进程情况</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure>
<h3 id="网页查看"><a href="#网页查看" class="headerlink" title="网页查看"></a>网页查看</h3><p>启动后可以在本地浏览器访问以下地址：</p>
<p><a href="http://localhost:8088/cluster" target="_blank" rel="noopener">http://localhost:8088/cluster</a></p>
<p><a href="http://localhost:50070" target="_blank" rel="noopener">http://localhost:50070</a></p>
<p><a href="http://localhost:8042/node" target="_blank" rel="noopener">http://localhost:8042/node</a></p>
<h2 id="Hadoop-Hello-World例程"><a href="#Hadoop-Hello-World例程" class="headerlink" title="Hadoop Hello World例程"></a>Hadoop Hello World例程</h2><p>利用自带的java程序测试，官方给了一个计算单词个数的代码也可以测试</p>
<p>###建立测试文件上传到HDFS中</p>
<p>在本地建立文件，我创建的文件与内容如下</p>
<p>file01</p>
<p>Hello World Bye World dfss<br>dfsa</p>
<p>file02</p>
<p>hello test</p>
<p>dfs0</p>
<p>上传文件命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -put /User/liuce/input input #修改自己文件目录</span><br></pre></td></tr></table></figure>
<p>可以在刚才创建的目录下看到刚才上传的文件：/user/$(whoami)/input  #input自动生成的</p>
<h3 id="运行测试程序"><a href="#运行测试程序" class="headerlink" title="运行测试程序"></a>运行测试程序</h3><p>自带demo程序目录在</p>
<p>/usr/local/Cellar/hadoop/2.8.0/libexec/share/hadoop/mapreduce</p>
<p>运行测试程序</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar ./hadoop-mapreduce-examples-2.8.0.jar grep input output 'dfs[a-z.]+'</span><br></pre></td></tr></table></figure>
<p>测试程序是计算以dfs单词的个数，结果记录在/user/$(whoami)/out/part-r-00000</p>
<p>删除刚才生成的文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -rm -r /user/$(whoami)/input</span><br><span class="line">hdfs dfs -rm -r /user/$(whoami)/output</span><br></pre></td></tr></table></figure>
<h2 id="快速搭建方式"><a href="#快速搭建方式" class="headerlink" title="快速搭建方式"></a>快速搭建方式</h2><p>在推荐两种快速的方式</p>
<ol>
<li><p>安装docker，基于docker的hadoop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull sequenceiq/hadoop-docker:2.7.1</span><br><span class="line">docker run -it sequenceiq/hadoop-docker:2.7.1 /etc/bootstrap.sh -bash</span><br></pre></td></tr></table></figure>
</li>
<li><p>虚拟机直接启动</p>
<p>访问网站 <a href="https://bitnami.com/" target="_blank" rel="noopener">https://bitnami.com/</a> 搜索hadoop下载镜像，直接用相应的虚拟机启动。</p>
<p>运行hadoop启动命令就可以了，这种方式也可以方便搭建集群环境。</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Hadoop-安装&quot;&gt;&lt;a href=&quot;#Hadoop-安装&quot; class=&quot;headerlink&quot; title=&quot;Hadoop 安装&quot;&gt;&lt;/a&gt;Hadoop 安装&lt;/h2&gt;&lt;p&gt;系统macos 10.12.4，linux系统大体与此相似&lt;/p&gt;
&lt;figure 
    
    </summary>
    
    
      <category term="bigdata" scheme="http://cealiu.me/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>存储知识记录</title>
    <link href="http://cealiu.me/2017/09/03/%E5%AD%98%E5%82%A8%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95/"/>
    <id>http://cealiu.me/2017/09/03/存储知识记录/</id>
    <published>2017-09-03T14:19:22.000Z</published>
    <updated>2017-09-03T14:22:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>平时工作是做云计算相关的，最近在学习hadoop的知识看到hadoop的文件存储方式结合用过的ceph，elasticsearch做下存储相关知识的记录。</p>
<h2 id="块存储、文件存储、对象存储"><a href="#块存储、文件存储、对象存储" class="headerlink" title="块存储、文件存储、对象存储"></a>块存储、文件存储、对象存储</h2><h3 id="介绍："><a href="#介绍：" class="headerlink" title="介绍："></a>介绍：</h3><p>块存储：是以扇区为基础的，一个或连续的扇区组成一个块，概念来自于物理存储。</p>
<p>文件储存：是多个物理块组成逻辑块后形成文件存储，根据不同的概念及驱动形成入nfs，ext4等文件系统。</p>
<p>对象存储：结合上面两个优点，增加了元数据(metadata)服务器。</p>
<p>这里有个知乎上不错的回答：<a href="http://www.zhihu.com/question/21536660" target="_blank" rel="noopener">http://www.zhihu.com/question/21536660</a></p>
<h3 id="优缺点："><a href="#优缺点：" class="headerlink" title="优缺点："></a>优缺点：</h3><p>推荐生产环境ceph使用块存储、对象存储</p>
<p>文件级备份：</p>
<p>文件级备份是指在指定某些文件进行备份时，首先会查找每个文件逻辑块，其次物理块，由于逻辑块是分散在物理块上，而物理块也是分散在不同扇区上。需要一层一 层往下查找，最后才完成整个文件复制。文件级备份时比较费时间，效率不高，实时性不强，备份时间长，且增量备份时，单文件某一小部份修改，不会只备份修改 部份，而整个文件都备份。</p>
<p>块级备份：</p>
<p>块级备份是指物理块复制，效率高，实时性强，备份时间短，且增量备份时，只备份修改过的物理块。</p>
<h2 id="ceph、hadoop、elasticsearch"><a href="#ceph、hadoop、elasticsearch" class="headerlink" title="ceph、hadoop、elasticsearch"></a>ceph、hadoop、elasticsearch</h2><p>hadoop：分布式存储主要适用于一次写入多次读取的场合（后续可能会增加其他数据处理方式），有数据块的概念(64M为一块，可配置)，将大文件分割为多个块进行存储；namenode内存中存放datanode数据索引，存储大小瓶颈来自namenode内存大小。</p>
<p>ceph：支持块存储、文件存储、对象存储；与hadoop相似的是块存储，不过更接近于物理块的概念；ceph的块驱动基于RBD（介绍<a href="http://www.sebastien-han.fr/blog/2016/03/28/ceph-jewel-preview-ceph-rbd-mirroring" target="_blank" rel="noopener">http://www.sebastien-han.fr/blog/2016/03/28/ceph-jewel-preview-ceph-rbd-mirroring</a>）</p>
<p>hadoop的存储也可以换成ceph的块存储不过性能可能会下降。</p>
<p>elasticsearch：更接近于nosql的数据库，不过分布式存储也是切片保存数据（介绍<a href="https://kibana.logstash.es/content/elasticsearch/principle/" target="_blank" rel="noopener">https://kibana.logstash.es/content/elasticsearch/principle/</a>）；查询的时候还有hadoop-elasticsearch插件感觉上是将logstash替换为了hadoop（理解的不知道对不对）。</p>
<h3 id="最后："><a href="#最后：" class="headerlink" title="最后："></a>最后：</h3><p>以上是工作中接触过的一些分布式存储的系统，要是想更深层次的理解一些知识还是要看一些理论行的东西如CAP，数据一致性存储等。</p>
<p>以上有什么说的不对的请指正，大家共同学习。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;平时工作是做云计算相关的，最近在学习hadoop的知识看到hadoop的文件存储方式结合用过的ceph，elasticsearch做下存储相关知识的记录。&lt;/p&gt;
&lt;h2 id=&quot;块存储、文件存储、对象存储&quot;&gt;&lt;a href=&quot;#块存储、文件存储、对象存储&quot; class=&quot;
    
    </summary>
    
    
      <category term="cloud" scheme="http://cealiu.me/tags/cloud/"/>
    
  </entry>
  
  <entry>
    <title>感知机算法</title>
    <link href="http://cealiu.me/2017/09/02/%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%AE%97%E6%B3%95/"/>
    <id>http://cealiu.me/2017/09/02/感知机算法/</id>
    <published>2017-09-02T13:52:44.000Z</published>
    <updated>2018-09-05T14:06:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>上节说了下Sigmoid函数做分类器，来做感知机学习(&lt;&lt;李航.统计学习方法&gt;&gt;)</p>
<h3 id="什么是感知机"><a href="#什么是感知机" class="headerlink" title="什么是感知机"></a>什么是感知机</h3><p>感知机是二分类的线形分类模型，其输入为实例的特征向量，输出为实例的类别，取+1和-1二值。</p>
<p>定义：假设输入空间（特征空间）是$x \subseteq R^n $,输出空间是$Y={+1,-1}$。输入$x \in \chi$表示实例的特征向量，对应于输入空间（特征空间）的点；输出$y \in Y$实例的类别。由输入空间到输出空间的如下函数</p>
<p>$$f(x) = sign(w.x+b)$$</p>
<p>称为感知机。其中，w和b为感知机模型参数，$w \in R^n$叫做权值(weight)或权值向量(weight vector)，$b \in R$叫作偏置(bias)，w.x表示w和x的内积。sign是符号函数，即<br>$$<br>\begin{equation}<br>sign(x)=\begin{cases}<br>+1&amp; x\ge0\\<br>-1&amp; x&lt;0<br>\end{cases}<br>\end{equation}<br>$$</p>
<h3 id="感知机算法"><a href="#感知机算法" class="headerlink" title="感知机算法"></a>感知机算法</h3><p>输入：训练数据集$T={(x_1,y_1),(x_2,y_2,)…(x_N,y_N)}$，其中$x_i \in \chi=R^n,y_i \in Y={-1,+1}$,i=1,2,…N;学习率$\eta(0&lt;\eta\leq1)$;</p>
<p>输出：w，b；感知机模型$f(x)=sign(w*x + b)$.</p>
<ol>
<li>选取初值$w_0,b_0$</li>
<li>在训练集中选取数据$(x_i,y_i)$</li>
<li>如果$y_i(w*x_i)+b\leq0$</li>
</ol>
<p>$$<br>w \gets w+\eta y_{i}x_i\\<br>b \gets b+\eta y_i<br>$$</p>
<ol>
<li>转至（2），直至训练集中没有误分类点。</li>
</ol>
<p>解释：当一个实例点被误分类，即位于分离超平面的错误一侧时，则调整w,b的值，使分离超平面向该误分类点的一侧移动，以减少该误分类点与超平面间的距离，直至超平面越过该误分类点使其被正确分类。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上节说了下Sigmoid函数做分类器，来做感知机学习(&amp;lt;&amp;lt;李航.统计学习方法&amp;gt;&amp;gt;)&lt;/p&gt;
&lt;h3 id=&quot;什么是感知机&quot;&gt;&lt;a href=&quot;#什么是感知机&quot; class=&quot;headerlink&quot; title=&quot;什么是感知机&quot;&gt;&lt;/a&gt;什么是感知机&lt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://cealiu.me/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Logistic回归和Sigmoid函数的理解</title>
    <link href="http://cealiu.me/2017/09/01/Logistic%E5%9B%9E%E5%BD%92%E5%92%8CSigmoid%E5%87%BD%E6%95%B0%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>http://cealiu.me/2017/09/01/Logistic回归和Sigmoid函数的理解/</id>
    <published>2017-09-01T06:02:21.000Z</published>
    <updated>2017-09-03T14:13:35.000Z</updated>
    
    <content type="html"><![CDATA[<p>看《机器学习实战》一书的Logistic回归记录下自己的理解，书上的例子用的是二维向量；该方法预测用的是Sigmoid函数（信号与系统的阶跃函数）。<br>$$<br>\sigma(z) = \cfrac{1}{1  +e^{-z}}<br>$$</p>
<p>Sigmoid函数的输入记为z，下面公式用于确定z：<br>$$<br>z = w_{0}x_{0} + w_{1}x_{1} + w_{2}x_{2} + …+ w_{n}x_{n}<br>$$</p>
<p>书上用的梯度上升算法确定系数w的数值。<br>$$<br>w = w + \alpha\delta f(w)<br>$$<br>该算法一直迭代找出w的系数，代码里是w（n，1），$\alpha = 0.001$ 循环500次得出系数矩阵。</p>
<p>该函数二维上就是在一些散点中画一条线来划分出不同的特征点，我们要找W就是这条线的系数。</p>
<p>书上给的给出的代码例程不能很好的运行，我做了简单的修改最后结果如下图：</p>
<p>修改过的源码上传到我的GitHub了<a href="https://github.com/cealiu/machinelearn/tree/master/Ch05" target="_blank" rel="noopener">地址</a></p>
<p><img src="/images/Logistic_1.png" alt=""></p>
<p>因为这个解法要迭代全部数据计算量比较大，后面的优化都是为了减少计算量做的比较好理解了就不在这里说明了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;看《机器学习实战》一书的Logistic回归记录下自己的理解，书上的例子用的是二维向量；该方法预测用的是Sigmoid函数（信号与系统的阶跃函数）。&lt;br&gt;$$&lt;br&gt;\sigma(z) = \cfrac{1}{1  +e^{-z}}&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;Sigmoi
    
    </summary>
    
    
      <category term="机器学习" scheme="http://cealiu.me/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>opentack节点扩容后热迁移异常</title>
    <link href="http://cealiu.me/2017/09/01/opentack%E8%8A%82%E7%82%B9%E6%89%A9%E5%AE%B9%E5%90%8E%E7%83%AD%E8%BF%81%E7%A7%BB%E5%BC%82%E5%B8%B8/"/>
    <id>http://cealiu.me/2017/09/01/opentack节点扩容后热迁移异常/</id>
    <published>2017-09-01T02:27:37.000Z</published>
    <updated>2017-09-01T02:47:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>扩容完成后旧计算节点上的虚机无法正常热迁移到新计算节点上</p>
<p>故障原因为：新旧节点的qemu版本存在差异。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep kvm</span><br></pre></td></tr></table></figure>
<p>qemu-kvm-2.5.1-1.1.el7.x86_64</p>
<p>libvirt-daemon-kvm-1.3.1-1.el7.centos.es.x86_64</p>
<p>qemu-kvm-common-2.5.1-1.1.el7.x86_64</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep kvm</span><br></pre></td></tr></table></figure>
<p>qemu-kvm-2.5.1-1.el7.es.x86_64</p>
<p>libvirt-daemon-kvm-1.3.1-1.el7.centos.es.x86_64</p>
<p>qemu-kvm-common-2.5.1-1.el7.es.x86_64</p>
<p>openstack虚机热迁移节点要求（摘录三条）:</p>
<ol>
<li><p>源和目标节点的 CPU 类型要一致。</p>
</li>
<li><p>源和目标节点的 Libvirt 版本要一致。</p>
</li>
<li><p>源和目标节点能相互识别对方的主机名称，比如可以在 /etc/hosts 中加入对方的条目。</p>
<p>迁移失败原因是第2条不满足。</p>
<p>升级qumu版本后解决，blog留作记录。</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;扩容完成后旧计算节点上的虚机无法正常热迁移到新计算节点上&lt;/p&gt;
&lt;p&gt;故障原因为：新旧节点的qemu版本存在差异。&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span c
    
    </summary>
    
    
      <category term="cloud" scheme="http://cealiu.me/tags/cloud/"/>
    
  </entry>
  
  <entry>
    <title>python 发送邮件出现Connection reset by peer解决</title>
    <link href="http://cealiu.me/2017/08/31/python-%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E5%87%BA%E7%8E%B0Connection-reset-by-peer%E8%A7%A3%E5%86%B3/"/>
    <id>http://cealiu.me/2017/08/31/python-发送邮件出现Connection-reset-by-peer解决/</id>
    <published>2017-08-31T13:17:37.000Z</published>
    <updated>2017-08-31T13:44:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>​       利用python自带的stmp模块发送邮件成功，但是在添加附件后发送失败。运行代码后提示出现connection reset by peer错误，查看后台服务器发现邮件服务器直接关闭了链接。</p>
<p>​       网上查找发现对于此问题的解释多是因为socket，web连接问题。后经排查后发现stmp协议使用的端口号是25：这里贴一段关于SMTP协议的介绍STMP协议介绍</p>
<p>​      下面连接邮件服务器一定要写上邮件端口号25<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">smtp.connect(smtpserver,<span class="string">"25"</span>)</span><br></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;​       利用python自带的stmp模块发送邮件成功，但是在添加附件后发送失败。运行代码后提示出现connection reset by peer错误，查看后台服务器发现邮件服务器直接关闭了链接。&lt;/p&gt;
&lt;p&gt;​       网上查找发现对于此问题的解释多是因为
    
    </summary>
    
    
      <category term="python" scheme="http://cealiu.me/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://cealiu.me/2017/08/30/hello-world/"/>
    <id>http://cealiu.me/2017/08/30/hello-world/</id>
    <published>2017-08-30T12:19:34.000Z</published>
    <updated>2017-09-01T16:12:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>用hexo和github搭建了一个静态博客，程序员惯用helloworld例程那就拿之前在知乎写简单写的一个回答放在这里吧，当作熟悉hexo博客和markdown语法了；后续会将开源中国上的和笔记软件记录的内容放上来。</p>
<h2 id="韩国灾难电影推荐"><a href="#韩国灾难电影推荐" class="headerlink" title="韩国灾难电影推荐"></a>韩国灾难电影推荐</h2><p>最近在腾讯视频上看了部韩国电影《铁线虫入侵》仔细回想发现之前看过不少类似韩国灾难电影这里一并推荐出来吧。</p>
<h3 id="《铁线虫入侵》"><a href="#《铁线虫入侵》" class="headerlink" title="《铁线虫入侵》"></a>《铁线虫入侵》</h3><p>关于人体寄生虫的故事</p>
<p><img src="/images/tiexianchongruqin.jpg" alt=""></p>
<h3 id="《流感》"><a href="#《流感》" class="headerlink" title="《流感》"></a>《流感》</h3><p>讲传染病的故事，让人想起之前的非典不过电影比较夸张</p>
<p><img src="/images/liugan.jpg" alt=""></p>
<h3 id="《釜山行》"><a href="#《釜山行》" class="headerlink" title="《釜山行》"></a>《釜山行》</h3><p>号称亚洲首部丧尸片</p>
<p><img src="/images/fushanxing.jpg" alt=""></p>
<h3 id="《隧道》"><a href="#《隧道》" class="headerlink" title="《隧道》"></a>《隧道》</h3><p>类似井下求生的故事</p>
<p><img src="/images/suidao.jpg" alt=""></p>
<h3 id="《汉江怪物》"><a href="#《汉江怪物》" class="headerlink" title="《汉江怪物》"></a>《汉江怪物》</h3><p>大家一起打怪兽</p>
<p><img src="/images/hanjiangguaiwu.jpg" alt=""></p>
<h3 id="《潘多拉》"><a href="#《潘多拉》" class="headerlink" title="《潘多拉》"></a>《潘多拉》</h3><p>讲述核电站核泄漏的故事</p>
<p><img src="/images/panduola.jpg" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;用hexo和github搭建了一个静态博客，程序员惯用helloworld例程那就拿之前在知乎写简单写的一个回答放在这里吧，当作熟悉hexo博客和markdown语法了；后续会将开源中国上的和笔记软件记录的内容放上来。&lt;/p&gt;
&lt;h2 id=&quot;韩国灾难电影推荐&quot;&gt;&lt;a hr
    
    </summary>
    
    
      <category term="影视" scheme="http://cealiu.me/tags/%E5%BD%B1%E8%A7%86/"/>
    
  </entry>
  
  <entry>
    <title>ELK排障记录</title>
    <link href="http://cealiu.me/2017/04/08/ELK%E6%8E%92%E9%9A%9C%E8%AE%B0%E5%BD%95/"/>
    <id>http://cealiu.me/2017/04/08/ELK排障记录/</id>
    <published>2017-04-08T08:33:52.000Z</published>
    <updated>2017-09-08T09:10:06.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景介绍："><a href="#背景介绍：" class="headerlink" title="背景介绍："></a>背景介绍：</h2><p>之前公司安全团队用ELK来收集ngnix，tomcat，防火墙等的接入日志来做一些安全风控的告警操作，接手后有次报告说有个IP的机器一直没有产生日志出来，因此做了简单的排查顺便在熟悉下架构。</p>
<p>公司用的审计接入日志的ELK架构图如下：</p>
<p><img src="/images/ELK_structure.png" alt=""></p>
<p>架构基本属于主流的应用不过logstash吐日志分别到Kafka集群和ossec集群，这样做的目的是Kafka用来削峰，ossec用来做安全分析发现问题后用告警平台发送相应信息到责任人。</p>
<h2 id="处理："><a href="#处理：" class="headerlink" title="处理："></a>处理：</h2><p>因为是在kibana展示上发现部分日志未展示，所以我们先检查了所有logstash shipper节点的日志情况发现日志时间戳连续没问题，es集群里缺少相应时间的部分日志，之后ossec上查看发现有部分日志缺失判定是logstash吐日志出现问题。</p>
<p>排查shipper各个节点时发现一台机器的logstash进程down了，重启后问题解决。</p>
<p>建议后期监控logstash进程或者修改配置。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景介绍：&quot;&gt;&lt;a href=&quot;#背景介绍：&quot; class=&quot;headerlink&quot; title=&quot;背景介绍：&quot;&gt;&lt;/a&gt;背景介绍：&lt;/h2&gt;&lt;p&gt;之前公司安全团队用ELK来收集ngnix，tomcat，防火墙等的接入日志来做一些安全风控的告警操作，接手后有次报告
    
    </summary>
    
    
      <category term="日志" scheme="http://cealiu.me/tags/%E6%97%A5%E5%BF%97/"/>
    
  </entry>
  
</feed>
